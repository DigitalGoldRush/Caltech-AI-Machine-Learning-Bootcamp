{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What Is Ensemble Learning?\n",
    "Ensemble techniques combine individual models to improve the stability and predictive power of the model.\n",
    "\n",
    "## Ideology Behind Ensemble Learning:\n",
    "Certain models do well in modeling one aspect of the data, while others do well in modeling another.\n",
    "\n",
    "Instead of learning a single complex model, learn several simple models and combine their output to produce the final decision.\n",
    "\n",
    "Individual model variances and biases are balanced by the strength of other models in ensemble learning.\n",
    "\n",
    "Ensemble learning will provide a composite prediction where the final accuracy is better than the accuracy of individual models.\n",
    "\n",
    "## Significance of Ensemble Learning\n",
    "    Robustness\n",
    "    \n",
    "        Ensemble models incorporate the predictions from all the base learners\n",
    "    \n",
    "    Accuracy\n",
    "    \n",
    "        Ensemble models deliver accurate predictions and have improved performances\n",
    "\n",
    "### Ensemble Learning Methods\n",
    "Techniques for creating an ensemble model\n",
    "\n",
    "Combine all weak learners to form an ensemble, or create an ensemble of well-chosen strong and diverse models\n",
    "\n",
    "### Steps Involved in Ensemble Methods\n",
    "Every ensemble algorithm consists of two steps:\n",
    "    \n",
    "    Producing a cohort of predictions using simple ML algorithms\n",
    "    \n",
    "    Combining the predictions into one aggregated model\n",
    "\n",
    "The ensemble can be achieved through several techniques.\n",
    "\n",
    "### Types of Ensemble Methods\n",
    "\n",
    "    Averaging\n",
    "\n",
    "    Weighted Averaging\n",
    "\n",
    "## Bagging Algorithms\n",
    "Bootstrap Aggregation or bagging involves taking multiple samples from your training dataset (with replacement) and training a model for each sample.\n",
    "\n",
    "The final output prediction is averaged across the predictions of all of the submodels.\n",
    "\n",
    "The three bagging models covered in this section are as follows:\n",
    "    \n",
    "    Bagged Decision Trees\n",
    "    \n",
    "    Random Forest\n",
    "    \n",
    "    Extra Trees\n",
    "\n",
    "1. Bagged Decision Trees\n",
    "\n",
    "Bagging performs best with algorithms that have a high variance. A popular example is decision trees, often constructed without pruning.\n",
    "\n",
    "Below, you can see an example of using the BaggingClassifier with the Classification and Regression Trees algorithm\n",
    "(DecisionTreeClassifier). A total of 100 trees are created.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaeldionne/opt/anaconda3/envs/sklearn_env/lib/python3.9/site-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "/Users/michaeldionne/opt/anaconda3/envs/sklearn_env/lib/python3.9/site-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "/Users/michaeldionne/opt/anaconda3/envs/sklearn_env/lib/python3.9/site-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "/Users/michaeldionne/opt/anaconda3/envs/sklearn_env/lib/python3.9/site-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "/Users/michaeldionne/opt/anaconda3/envs/sklearn_env/lib/python3.9/site-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "/Users/michaeldionne/opt/anaconda3/envs/sklearn_env/lib/python3.9/site-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "/Users/michaeldionne/opt/anaconda3/envs/sklearn_env/lib/python3.9/site-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "/Users/michaeldionne/opt/anaconda3/envs/sklearn_env/lib/python3.9/site-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "/Users/michaeldionne/opt/anaconda3/envs/sklearn_env/lib/python3.9/site-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "/Users/michaeldionne/opt/anaconda3/envs/sklearn_env/lib/python3.9/site-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7578263841421736\n"
     ]
    }
   ],
   "source": [
    "#Bagged Decision Trees for Classification\n",
    "import pandas\n",
    "from sklearn import model_selection\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\"\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "dataframe = pandas.read_csv(url, names=names)\n",
    "array = dataframe.values\n",
    "X = array[:,0:8]\n",
    "Y = array[:,8]\n",
    "seed = 7\n",
    "kfold = model_selection.KFold(n_splits=10, random_state=seed, shuffle=True)\n",
    "cart = DecisionTreeClassifier()\n",
    "num_trees = 100\n",
    "model = BaggingClassifier(base_estimator=cart, n_estimators=num_trees, random_state=seed)\n",
    "results = model_selection.cross_val_score(model, X, Y, cv=kfold)\n",
    "print(results.mean())\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Random Forest\n",
    "\n",
    "Random forest is an extension of bagged decision trees.\n",
    "\n",
    "Samples of the training dataset are taken with replacement, but the trees are constructed in a way that reduces the correlation between\n",
    "individual classifiers. Specifically, rather than greedily choosing the best split point in the construction of the tree, only a random subset of\n",
    "features is considered for each split.\n",
    "\n",
    "You can construct a Random Forest model for classification using the RandomForestClassifier class.\n",
    "\n",
    "The example below provides a sample of Random Forest for classification with 100 trees and split points chosen from a random selection\n",
    "of three features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7682330827067669\n"
     ]
    }
   ],
   "source": [
    "#Random Forest Classification\n",
    "import pandas\n",
    "from sklearn import model_selection\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\"\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "dataframe = pandas.read_csv(url, names=names)\n",
    "array = dataframe.values\n",
    "X = array[:,0:8]\n",
    "Y = array[:,8]\n",
    "seed = 7\n",
    "num_trees = 100\n",
    "max_features = 3\n",
    "kfold = model_selection.KFold(n_splits=10, random_state=seed, shuffle=True)\n",
    "model = RandomForestClassifier(n_estimators=num_trees, max_features=max_features)\n",
    "results = model_selection.cross_val_score(model, X, Y, cv=kfold)\n",
    "print(results.mean())\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Extra Trees\n",
    "\n",
    "Extra Trees are another modification of bagging where random trees are constructed from samples of the training dataset.\n",
    "\n",
    "You can construct an Extra Trees model for classification using the ExtraTreesClassifier class.\n",
    "\n",
    "The example below provides a demonstration of extra trees with a tree set of 100 and splits chosen from seven random features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7577922077922079\n"
     ]
    }
   ],
   "source": [
    "#Extra Trees Classification\n",
    "import pandas\n",
    "from sklearn import model_selection\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\"\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "dataframe = pandas.read_csv(url, names=names)\n",
    "array = dataframe.values\n",
    "X = array[:,0:8]\n",
    "Y = array[:,8]\n",
    "seed = 7\n",
    "num_trees = 100\n",
    "max_features = 7\n",
    "kfold = model_selection.KFold(n_splits=10, random_state=seed, shuffle=True)\n",
    "model = ExtraTreesClassifier(n_estimators=num_trees, max_features=max_features)\n",
    "results = model_selection.cross_val_score(model, X, Y, cv=kfold)\n",
    "print(results.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sklearn_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
